{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/jakoliendenhollander/capstone/capstone')\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "import tidy_functions.load_data\n",
    "import tidy_functions.clean_data\n",
    "import tidy_functions.merge_data\n",
    "import tidy_functions.feature_engineering\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "pd.set_option('display.max_columns', None) # To display all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in survey data completed.\n",
      "Read in covid data completed.\n",
      "Read in mask wearing requirements data completed.\n"
     ]
    }
   ],
   "source": [
    "# Reading in survey data from csv into a dictionary of dataframes.\n",
    "dfs_country = tidy_functions.load_data.load_survey_data(\"/Users/jakoliendenhollander/capstone/capstone/data/CMU_Global_data/Full_Survey_Data/country/smooth/\", \"country\")\n",
    "\n",
    "# Concatenating individuals dataframes from the dictionary into one dataframe for regions.\n",
    "survey_data = pd.concat(dfs_country, ignore_index=True)\n",
    "\n",
    "# Corona stats\n",
    "covid_cases = pd.read_csv(\"/Users/jakoliendenhollander/capstone/capstone/data/Corona_stats/owid-covid-data.csv\")\n",
    "print('Read in covid data completed.')\n",
    "\n",
    "# Mask wearing requirements\n",
    "mask_wearing_requirements = pd.read_csv(\"/Users/jakoliendenhollander/capstone/capstone/data/data-nbhtq.csv\")\n",
    "print('Read in mask wearing requirements data completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs before update: 152923\n",
      "NaNs after update: 0\n",
      "Updated NaNs in wear_mask_all_time.\n",
      "NaNs removed.\n",
      "Step 1 of cleaning requirements completed.\n",
      "Step 2 of cleaning requirements completed.\n",
      "Step 3 of cleaning requirements completed.\n",
      "Step 4 of cleaning requirements completed.\n",
      "Step 5 of cleaning requirements completed.\n",
      "Step 6 of cleaning requirements completed.\n",
      "Creating dictionaries for hdi completed.\n",
      "Creating dictionaries for hdi-levels completed.\n"
     ]
    }
   ],
   "source": [
    "# Survey data\n",
    "survey_data = tidy_functions.clean_data.delete_other_gender(survey_data)\n",
    "survey_data = tidy_functions.clean_data.deal_with_NaNs_masks(survey_data)\n",
    "\n",
    "# Corona stats\n",
    "covid_cases = tidy_functions.clean_data.deal_with_NaNs_corona_stats(covid_cases)\n",
    "\n",
    "# Mask wearing requirements\n",
    "mask_wearing_requirements = tidy_functions.clean_data.prepare_mask_req(mask_wearing_requirements)\n",
    "mask_wearing_requirements = tidy_functions.clean_data.dummies_mask_req(mask_wearing_requirements)\n",
    "mask_wearing_requirements = tidy_functions.clean_data.dummies_public_mask_req(mask_wearing_requirements)\n",
    "mask_wearing_requirements = tidy_functions.clean_data.dummies_indoors_mask_req(mask_wearing_requirements)\n",
    "mask_wearing_requirements = tidy_functions.clean_data.dummies_transport_mask_req(mask_wearing_requirements)\n",
    "mask_wearing_requirements = tidy_functions.clean_data.data_types_mask_req(mask_wearing_requirements)\n",
    "\n",
    "# HDI\n",
    "hdi_data = tidy_functions.clean_data.rename_hdi_countries(\"/Users/jakoliendenhollander/capstone/capstone/data/\",\"hdro_statistical_data_tables_1_15_d1_d5.xlsx\")\n",
    "dict_hdi = tidy_functions.clean_data.create_hdi_dict(hdi_data)\n",
    "dict_hdi_levels = tidy_functions.clean_data.create_hdi_levels_dict(hdi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging corona stats completed.\n",
      "Merging mask wearing requirements completed.\n",
      "Creating hdi list completed.\n",
      "Creating hdi-level list completed.\n"
     ]
    }
   ],
   "source": [
    "covid_merge = tidy_functions.merge_data.merge_corona_stats(survey_data,covid_cases)\n",
    "requirements_merge = tidy_functions.merge_data.merge_mask_req(covid_merge,mask_wearing_requirements)\n",
    "hdi_merge = tidy_functions.merge_data.create_hdi_columns(requirements_merge, dict_hdi, dict_hdi_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month column created.\n",
      "Feature engineering completed.\n"
     ]
    }
   ],
   "source": [
    "date_fixed = tidy_functions.feature_engineering.insert_month(hdi_merge)\n",
    "requirement_date = tidy_functions.feature_engineering.add_requirement_by_date(date_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = requirement_date.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"age_bucket\"]==\"overall\"]\n",
    "df = df[df[\"gender\"]==\"overall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [\"date\"]\n",
    "\n",
    "columns_general = [\"iso_code\", \"hdi\", \"median_age\"]\n",
    "\n",
    "columns_general_no_iso = [\"hdi\", \"median_age\"]\n",
    "\n",
    "columns_social_distancing = [\"smoothed_pct_worked_outside_home_weighted\", \"smoothed_pct_grocery_outside_home_weighted\", \"smoothed_pct_ate_outside_home_weighted\", \n",
    "                             \"smoothed_pct_attended_public_event_weighted\", \"smoothed_pct_used_public_transit_weighted\", \n",
    "                             \"smoothed_pct_direct_contact_with_non_hh_weighted\", \"smoothed_pct_no_public_weighted\"]\n",
    "\n",
    "columns_mask_wearing = [\"smoothed_pct_wear_mask_all_time_weighted\", \"smoothed_pct_wear_mask_most_time_weighted\"]\n",
    "\n",
    "columns_mask_req = [\"cur_mask_recommended\", \"cur_mask_not_required\", \"cur_mask_not_required_recommended\", \"cur_mask_not_required_universal\", \n",
    "                    \"cur_mask_required_part_country\", \"cur_mask_everywhere_in_public\", \"cur_mask_public_indoors\", \"cur_mask_public_transport\"]\n",
    "\n",
    "columns_pred = [\"total_cases_per_million\"]\n",
    "\n",
    "columns_interest = date + columns_general + columns_social_distancing + columns_mask_wearing + columns_mask_req + columns_pred\n",
    "\n",
    "columns_rev_scale = columns_general_no_iso + columns_social_distancing + columns_mask_wearing + columns_mask_req + columns_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df[columns_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one day ago\n",
    "previous_day = []\n",
    "\n",
    "for i in range(len(df_select)):\n",
    "    \n",
    "    if df_select.at[df_select.index[i],'date'] > df_select[df_select['iso_code'] == df_select.at[df_select.index[i],'iso_code']].date.min():\n",
    "        yesterday = df_select.at[df_select.index[i],'date'] - timedelta(days=1)\n",
    "        iso_code = df_select.at[df_select.index[i],'iso_code']\n",
    "        \n",
    "        if yesterday in df_select[df_select[\"iso_code\"] == iso_code].date.values:\n",
    "            value = df_select.loc[(df_select.date == yesterday) & (df_select.iso_code == iso_code), 'total_cases_per_million']\n",
    "            previous_day = [*previous_day, *value.values]\n",
    "        else:\n",
    "            previous_day = [*previous_day, 'NaN']\n",
    "    else:\n",
    "        previous_day = [*previous_day, 'NaN']\n",
    "        \n",
    "df_select['previous_day'] = previous_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one week ago\n",
    "previous_7days = []\n",
    "\n",
    "for i in range(len(df_select)):\n",
    "    \n",
    "    if df_select.at[df_select.index[i],'date'] > df_select[df_select['iso_code'] == df_select.at[df_select.index[i],'iso_code']].date.min() + timedelta(days=6):\n",
    "        last_week = df_select.at[df_select.index[i],'date'] - timedelta(days=7)\n",
    "        iso_code = df_select.at[df_select.index[i],'iso_code']\n",
    "        \n",
    "        if last_week in df_select[df_select[\"iso_code\"] == iso_code].date.values:\n",
    "            value = df_select.loc[(df_select.date == last_week) & (df_select.iso_code == iso_code), 'total_cases_per_million']\n",
    "            previous_7days = [*previous_7days, *value.values]\n",
    "        else:\n",
    "            previous_7days = [*previous_7days, 'NaN']\n",
    "    else:\n",
    "        previous_7days = [*previous_7days, 'NaN']\n",
    "        \n",
    "df_select['previous_7days'] = previous_7days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one month\n",
    "previous_30days = []\n",
    "\n",
    "for i in range(len(df_select)):\n",
    "    \n",
    "    if df_select.at[df_select.index[i],'date'] > df_select[df_select['iso_code'] == df_select.at[df_select.index[i],'iso_code']].date.min() + timedelta(days=29):\n",
    "        last_month = df_select.at[df_select.index[i],'date'] - timedelta(days=30)\n",
    "        iso_code = df_select.at[df_select.index[i],'iso_code']\n",
    "        \n",
    "        if last_month in df_select[df_select[\"iso_code\"] == iso_code].date.values:\n",
    "            value = df_select.loc[(df_select.date == last_month) & (df_select.iso_code == iso_code), 'total_cases_per_million']\n",
    "            previous_30days = [*previous_30days, *value.values]\n",
    "        else:\n",
    "            previous_30days = [*previous_30days, 'NaN']\n",
    "    else:\n",
    "        previous_30days = [*previous_30days, 'NaN']\n",
    "        \n",
    "df_select['previous_30days'] = previous_30days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df_select.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.previous_day = pd.to_numeric(df_time.previous_day, errors='coerce')\n",
    "df_time.previous_7days = pd.to_numeric(df_time.previous_7days, errors='coerce')\n",
    "df_time.previous_30days = pd.to_numeric(df_time.previous_30days, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df_time.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df_time.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_iso = df_time.drop(\"iso_code\", axis=1)\n",
    "df_no_date = df_no_iso.drop(\"date\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the data into train and test data\n",
    "train_size = int(len(df_no_date) * 0.80)\n",
    "test_size = len(df_no_date) - train_size\n",
    "train, test = df_no_date[0:train_size], df_no_date[train_size:len(df_no_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14140, 22) (14140,) (3535, 22) (3535,)\n"
     ]
    }
   ],
   "source": [
    "#index the data into dependent and independent variables\n",
    "train_X, train_y = train.drop(\"total_cases_per_million\", axis=1), train[\"total_cases_per_million\"]\n",
    "test_X, test_y =  test.drop(\"total_cases_per_million\", axis=1), test[\"total_cases_per_million\"]\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_scale = [\"median_age\", \"smoothed_pct_worked_outside_home_weighted\", \"smoothed_pct_grocery_outside_home_weighted\", \n",
    "#            \"smoothed_pct_ate_outside_home_weighted\", \"smoothed_pct_attended_public_event_weighted\", \n",
    "#            \"smoothed_pct_used_public_transit_weighted\", \"smoothed_pct_direct_contact_with_non_hh_weighted\", \n",
    "#            \"smoothed_pct_no_public_weighted\", \"smoothed_pct_wear_mask_all_time_weighted\", \n",
    "#            \"smoothed_pct_wear_mask_most_time_weighted\", \"previous_day\",\"previous_7days\",\"previous_30days\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the values\n",
    "#scaler_X = MinMaxScaler()\n",
    "#train_X[to_scale] = scaler_X.fit_transform(train_X[to_scale])\n",
    "#test_X[to_scale] = scaler_X.transform(test_X[to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler_y = MinMaxScaler()\n",
    "#scaler_y.fit(train_y)\n",
    "#train_y = scaler_y.fit_transform(train_y)\n",
    "#test_y = scaler_y.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(criterion='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target transform wrapper \n",
    "wrapped_model = TransformedTargetRegressor(regressor=model,transformer=MinMaxScaler()) \n",
    "# use the target transform wrapper \n",
    "wrapped_model.fit(train_X, train_y) \n",
    "yhat = wrapped_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207.24249086421474"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(test_y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2633088235294119"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(207*83)/13600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone] *",
   "language": "python",
   "name": "conda-env-capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
